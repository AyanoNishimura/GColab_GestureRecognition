{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyanoNishimura/GColab_GestureRecognition/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mLab_LGyvZpW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* テストデータに偏りが無いかを確認する [ok]\n",
        "* best_loss, best_epoch をループの外に置いて記録しておく[ok]\n",
        "  * テストデータの学習率が一定(n = 32とか適当)epochで上がらない場合、学習を止める\n",
        "  * 実装したらちゃんと動いてるか少ないデータで確認する\n",
        "* 入力のsequence = 32 とする\n",
        "* fc層にsequence = 1 が入るようする\n",
        "* pooling層を5つ入れる\n",
        "  * conv, conv, poolingとかでいい\n",
        "  * 均一になるようにpooling層を入れる\n",
        "* conv層を 5, 10, 15,  20 に重ねる\n",
        "  * conv ksize =(3, 1), stride = (1,1) , padding=(1, 1)\n",
        "  * paddingは本当は入れない方がいい\n",
        "* lrは10^-2, 10^-4, 10^-6でやる\n",
        "* conv層チャネル数 8, 16, 32（すべて同じでおｋ）\n",
        "* weight decay を 0にする\n",
        "* 36通り試す"
      ]
    },
    {
      "metadata": {
        "id": "lIY2j50Lerar",
        "colab_type": "code",
        "outputId": "de38257d-b723-4ca5-d801-162387bfd065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Import Chainer \n",
        "from chainer import Chain, Variable, optimizers, serializers, datasets, training, cuda\n",
        "from chainer.training import extensions\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import Variable\n",
        "import chainer\n",
        "\n",
        "# Import NumPy and CuPy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from progressbar import ProgressBar\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# mout drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "print('Chainer version: ', chainer.__version__)\n",
        "print('GPU availability:', chainer.cuda.available)\n",
        "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "Chainer version:  5.0.0\n",
            "GPU availability: True\n",
            "cuDNN availablility: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s48JvSvxfofw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "variables"
      ]
    },
    {
      "metadata": {
        "id": "sN2qPMn6fpbw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "is_debug = True\n",
        "lr = 10 ** np.random.uniform(-6, -2)\n",
        "wd = 10 ** np.random.uniform(-8, -4)\n",
        "sequence = 10\n",
        "batch_size = 140 # gesture_num * n\n",
        "loop_time = 10\n",
        "epoch_num = 1000\n",
        "stop_epoch = 2\n",
        "\n",
        "# path\n",
        "models_path = '/gdrive/My Drive/DeepLearning/GestureRecognition/models/CNN/'\n",
        "output_filename = 'epoch_' + str(epoch_num) + '_lr_' + str(lr) + '_wd_' + str(wd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOdBL9n5fbc4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "models"
      ]
    },
    {
      "metadata": {
        "id": "lQfW4G7RfeUA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(chainer.Chain):\n",
        "  def __init__(self, n_out):\n",
        "    super(CNN, self).__init__()\n",
        "    with self.init_scope():\n",
        "      self.conv1 = L.Convolution2D(None, 1000, (2, 1), stride=(1, 1), pad=(0, 0))\n",
        "      self.conv2 = L.Convolution2D(None, 1500, (2, 1), stride=(1, 1), pad=(0, 0))\n",
        "      self.l1 = L.Linear(None, n_out)\n",
        "      \n",
        "  def forward(self, x_data, t_data):\n",
        "    x, t = Variable(cuda.to_gpu(x_data)), Variable(cuda.to_gpu(t_data))\n",
        "#     print(x.shape, t.shape)\n",
        "    \n",
        "    h = self.conv1(x)\n",
        "#     print(self.conv1.W.shape, self.conv1.b.shape)\n",
        "#     print(\"a: \", h.shape)\n",
        "#     h = F.local_response_normalization(h)\n",
        "#     print(\"b: \", h.shape)\n",
        "    h = F.relu(h)\n",
        "#     print(\"c: \", h.shape)\n",
        "    h = F.max_pooling_2d(h, (2, 1), stride=(2, 1))\n",
        "#     print(\"d: \", h.shape)\n",
        "    \n",
        "    h = self.conv2(h)\n",
        "#     print(\"e: \", h.shape)\n",
        "#     h = F.local_response_normalization(h)\n",
        "#     print(\"f: \", h.shape)\n",
        "    h = F.relu(h)\n",
        "#     print(\"g: \", h.shape)\n",
        "    h = F.max_pooling_2d(h, (2, 1), stride=(2, 1))\n",
        "#     print(\"h: \", h.shape)\n",
        "    \n",
        "    y = self.l1(h)\n",
        "    \n",
        "    return F.softmax_cross_entropy(y, t), F.accuracy(y, t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KL8JXhhsffGI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train"
      ]
    },
    {
      "metadata": {
        "id": "P1UIeIWAfgCY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(file_path):\n",
        "  train, test = get_train_test_data(file_path)\n",
        "  print('-'*5 +'data size'+ '-'*5)\n",
        "  print('train data: ', train.shape[0])\n",
        "  print('test data: ', test.shape[0])\n",
        "  \n",
        "  t_train = pd.DataFrame({'gesture': train['gesture'], 'participants': train['participants']})\n",
        "  x_train = train.drop('gesture', axis=1)\n",
        "  t_test = pd.DataFrame({'gesture': test['gesture'], 'participants': test['participants']})\n",
        "  x_test = test.drop('gesture', axis=1)\n",
        "\n",
        "  train_acc_list, train_loss_list, test_acc_list, test_loss_list = training(x_train, t_train, x_test, t_test)\n",
        "  \n",
        "  # show graph acc\n",
        "  plt.figure()\n",
        "  x = np.arange(len(train_acc_list))\n",
        "  plt.plot(x, train_acc_list, marker='o', label='train')\n",
        "  t = np.arange(len(test_acc_list))\n",
        "  plt.plot(t, test_acc_list, marker='+', label='test')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.ylim(-0.05, 1.0)\n",
        "  plt.savefig(models_path + output_filename + '_acc.png')\n",
        "  plt.close()\n",
        "  \n",
        "  plt.figure()\n",
        "  x = np.arange(len(train_loss_list))\n",
        "  plt.plot(x, train_loss_list, marker='o', color='r', label='train')\n",
        "  t = np.arange(len(test_loss_list))\n",
        "  plt.plot(t, test_loss_list, marker='+', color='b', label='test')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('loss')\n",
        "#   plt.ylim(0.0, 10.0)\n",
        "  plt.savefig(models_path + output_filename + '_loss.png')\n",
        "  plt.close()\n",
        "\n",
        "  print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XlJtpZmOjIRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 実際に学習を行う関数\n",
        "def training(x_train, t_train, x_test, t_test):\n",
        "  gesture_num = int(t_train['gesture'].max()) + 1\n",
        "  \n",
        "  print('-'*5 +'gesture num'+ '-'*5)\n",
        "  print(gesture_num)\n",
        "  print('-'*5 +'Hyper Parameter'+ '-'*5)\n",
        "  print('lr: ', lr)\n",
        "  print('weight decay: ', wd)\n",
        "  \n",
        "  # create model instance\n",
        "  model = CNN(gesture_num)\n",
        "  \n",
        "  # setting GPU\n",
        "  model.to_gpu()\n",
        "  \n",
        "  # setting optimizer\n",
        "  optimizer = chainer.optimizers.Adam(alpha=lr, weight_decay_rate=wd)\n",
        "  optimizer.setup(model)\n",
        "  \n",
        "  # training\n",
        "  best_loss, before_loss = 100000.0, 0.0\n",
        "  best_epoch, same_rate_continue_num = 0, 0\n",
        "  train_acc_list, train_loss_list = [], []\n",
        "  test_acc_list, test_loss_list = [], []\n",
        "  print('-'*5 +'train start'+ '-'*5)\n",
        "  for epoch in range(epoch_num):\n",
        "    best_epoch += 1\n",
        "    print('Epoch: %d' % (epoch+1))\n",
        "    \n",
        "    # set progress bar for train\n",
        "    prg = ProgressBar(0, batch_size * loop_time)\n",
        "    prg_num = 0\n",
        "    \n",
        "    loss, accuracy = forward(x_train, t_train, gesture_num, model, optimizer, prg, prg_num)\n",
        "    \n",
        "    train_loss_list.append(loss)\n",
        "    train_acc_list.append(accuracy)\n",
        "    \n",
        "    # set progress bar for test\n",
        "    prg = ProgressBar(0, int(len(x_test)/sequence))\n",
        "    prg_num = 0\n",
        "    \n",
        "    loss, accuracy = forward(x_test, t_test, gesture_num, model, optimizer, prg, prg_num, False)\n",
        "    \n",
        "    test_loss_list.append(loss)\n",
        "    test_acc_list.append(accuracy)\n",
        "    \n",
        "    # 一定数テストデータの学習率が上がらなかったら、学習を止める\n",
        "    if before_loss == loss:\n",
        "      same_rate_continue_num += 1\n",
        "    else:\n",
        "      same_rate_continue_num = 0\n",
        "    \n",
        "    # 良かったlossとepochの記録\n",
        "    if loss < best_loss:\n",
        "      best_loss = loss\n",
        "      best_epoch = epoch+1\n",
        "      \n",
        "    if same_rate_continue_num >= stop_epoch:\n",
        "      print('Best Epoch: ', best_epoch)\n",
        "      print('Best Test Loss: ', best_loss)\n",
        "      break\n",
        "      \n",
        "    before_loss = loss\n",
        "    \n",
        "  serializers.save_hdf5(models_path + output_filename, model)\n",
        "  return train_acc_list, train_loss_list, test_acc_list, test_loss_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2iXJ0vbGI9D3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# forwardの関数\n",
        "def forward(x_data, t_data, gesture_num, model, optimizer, prg, prg_num, is_train=True):\n",
        "  sum_accuracy, sum_loss, sum_batch_size = 0, 0, 0\n",
        "  x_batch, t_batch = [], []\n",
        "  current_gesture, batch_loop = 0, 0\n",
        "  if is_train:\n",
        "    batch_loop = batch_size * loop_time * sequence\n",
        "  else:\n",
        "    batch_loop = len(x_data)\n",
        "  \n",
        "  for i in range(0, batch_loop, sequence):\n",
        "    if is_train: # 学習時は均等にジェスチャーが入るようにバッチを作成する\n",
        "      current_gesture = int(math.floor(len(x_batch) / (batch_size / gesture_num)))\n",
        "#       print('current gesture: ', current_gesture)\n",
        "      index_list = t_data.loc[t_data['gesture'] == current_gesture].index\n",
        "      num = np.random.randint(index_list[0], index_list[-1]-sequence)\n",
        "      x = x_data.iloc[num:num+sequence]\n",
        "      t = t_data.iloc[num:num+sequence]\n",
        "    else: # テストデータは総なめする \n",
        "      x = x_data.iloc[i:i+sequence]\n",
        "      t = t_data.iloc[i:i+sequence]\n",
        "\n",
        "    if not len(x) < sequence:\n",
        "      x, t = get_sequence(x, t)\n",
        "\n",
        "      x_batch.append(x)\n",
        "      t_batch.append(t)\n",
        "    \n",
        "    if len(x_batch) == batch_size or i >= (batch_loop - 1) - sequence:\n",
        "      x_batch = np.reshape(x_batch, (len(x_batch), 75, sequence, 1))\n",
        "      t_batch = np.array(t_batch, dtype=np.int32)\n",
        "      t_batch = t_batch.reshape(-1)\n",
        "\n",
        "      # update progress bar\n",
        "      prg.update(prg_num)\n",
        "      prg_num = prg_num + len(x_batch)\n",
        "\n",
        "      # get loss and accuracy\n",
        "      loss, acc = model.forward(x_batch, t_batch)\n",
        "\n",
        "      if is_train:\n",
        "        model.zerograds()\n",
        "        loss.backward()\n",
        "        loss.unchain_backward()\n",
        "\n",
        "        optimizer.update()\n",
        "\n",
        "      sum_loss += float(loss.data) * len(x_batch)\n",
        "      sum_accuracy += float(acc.data) * len(x_batch)\n",
        "      sum_batch_size += len(x_batch)\n",
        "\n",
        "      x_batch, t_batch = [], []\n",
        "    \n",
        "  # show training data loss and accuracy\n",
        "  loss = sum_loss / sum_batch_size\n",
        "  accuracy = sum_accuracy / sum_batch_size\n",
        "  \n",
        "  str = 'train'\n",
        "  if not is_train:\n",
        "    str = 'test'\n",
        "  print(str + ' mean loss={}, accuracy={}'.format(loss, accuracy))\n",
        "    \n",
        "  return loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKizHeJVvhMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# バッチデータをフォーマットする\n",
        "def get_sequence(x_batch, t_batch):\n",
        "  x_batch = x_batch.drop('participants', axis=1)\n",
        "  x_batch = x_batch.values.astype(np.float32)\n",
        "  t_batch = t_batch.drop('participants', axis=1)\n",
        "  t_batch = t_batch.mode().iloc[0]\n",
        "  t_batch = t_batch.values.astype(np.int32)\n",
        "  t_batch = t_batch.reshape(-1)\n",
        "\n",
        "  return x_batch, t_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iG8UYKGfgVFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 学習用、検証用にファイルのデータを分ける\n",
        "def get_train_test_data(file_path):\n",
        "  data = pd.read_csv(file_path)\n",
        "  gesture_num = int(data['gesture'].max())\n",
        "  train = test = formatted_test = pd.DataFrame().reindex_like(data)[:0]\n",
        "  for index in range(0, gesture_num + 1):\n",
        "    tr, te = train_test_split(data.query('gesture == ' + str(index)), test_size=0.2, shuffle=False)\n",
        "    train = train.append(tr)\n",
        "    test = test.append(te)\n",
        "  train = train.reset_index(drop=True)\n",
        "  test = test.reset_index(drop=True)\n",
        "  \n",
        "  # テストデータの偏りをなくすため、一番データ数が少ないものに合わせる\n",
        "  test_data_min = len(test[test['gesture'] == 0])\n",
        "  for gesture in range(1, gesture_num+1):\n",
        "    if len(test[test['gesture'] == gesture]) < test_data_min:\n",
        "      test_data_min = len(test[test['gesture'] == gesture])\n",
        "      \n",
        "  # ランダムにテストデータを抽出する\n",
        "  for gesture in range(0, gesture_num+1):\n",
        "    t = test[test['gesture'] == gesture]\n",
        "    num = 0\n",
        "    if len(t)-test_data_min != 0:\n",
        "      num = np.random.randint(0, len(t)-test_data_min)\n",
        "    formatted_test = formatted_test.append(t.iloc[num:num+test_data_min])\n",
        "  formatted_test = formatted_test.reset_index(drop=True)\n",
        "  \n",
        "  # めっちゃ小さいデータを扱うとき\n",
        "#   train = train[100:121]\n",
        "#   train = formatted_test = test\n",
        "#   print(train)\n",
        "#   formatted_test = formatted_test[0:20]\n",
        "  \n",
        "  return train, formatted_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xi7YUiUwfke4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "main"
      ]
    },
    {
      "metadata": {
        "id": "xHAe4wWfflig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if is_debug:\n",
        "  file_path = '/gdrive/My Drive/DeepLearning/GestureRecognition/data/small/train_classification.csv'\n",
        "#   file_path = '/gdrive/My Drive/DeepLearning/GestureRecognition/data/trim/train_classification.csv'\n",
        "#   file_path = '/gdrive/My Drive/DeepLearning/GestureRecognition/data/small.csv'\n",
        "else:\n",
        "  file_path = '/gdrive/My Drive/DeepLearning/GestureRecognition/data/formatted/train_classification.csv'\n",
        "  \n",
        "train(file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}